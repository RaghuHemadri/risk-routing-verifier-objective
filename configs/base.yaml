# ============================================================
# R2V-Agent: Base Configuration
# ============================================================
# All benchmark-specific configs inherit from this file.

project:
  name: r2v-agent
  seed: 42
  output_dir: experiments/results
  checkpoint_dir: experiments/checkpoints
  log_dir: experiments/logs

# ---------- Model defaults ----------
policy:
  model_name: meta-llama/Llama-3.1-8B-Instruct
  max_seq_len: 4096
  lora:
    enabled: true
    r: 64
    alpha: 128
    dropout: 0.05
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  quantization:
    load_in_4bit: true
    bnb_4bit_compute_dtype: bfloat16
    bnb_4bit_quant_type: nf4

teacher:
  model_name: meta-llama/Llama-3.1-70B-Instruct
  # Or use API-based:
  # provider: openai
  # model_name: gpt-4o
  max_seq_len: 8192
  temperature: 0.7
  top_p: 0.95

verifier:
  # Phase 1: LLM-as-verifier (no training needed)
  # Phase 2: Distilled smaller verifier
  mode: llm_judge  # Options: llm_judge, trained
  llm_judge:
    model_name: meta-llama/Llama-3.1-70B-Instruct
    # Or API:
    # provider: openai
    # model_name: gpt-4o
  trained:
    backbone: meta-llama/Llama-3.1-8B-Instruct
    hidden_dim: 1024
    num_layers: 2
    dropout: 0.1
  multitask:
    step_weight: 0.3    # weight for step-level loss
    final_weight: 1.0   # weight for final-outcome loss

router:
  input_features:
    policy_hidden_dim: 256
    verifier_score: true
    entropy: true
    step_number: true
    token_count: true
  hidden_dims: [128, 64]
  dropout: 0.2
  calibration:
    temperature_scaling: true
    num_bins: 15

# ---------- Training defaults ----------
training:
  # Behavior cloning
  bc:
    epochs: 3
    batch_size: 4
    gradient_accumulation_steps: 8
    learning_rate: 2.0e-5
    weight_decay: 0.01
    warmup_ratio: 0.05
    max_grad_norm: 1.0
    scheduler: cosine

  # DPO preference distillation
  preference:
    enabled: true
    beta: 0.1
    num_candidates: 8
    epochs: 2
    batch_size: 2
    gradient_accumulation_steps: 16
    learning_rate: 5.0e-6

  # Tool-consistency regularization
  consistency:
    enabled: true
    lambda_cons: 0.1
    num_tool_seeds: 2

  # Verifier training
  verifier:
    epochs: 5
    batch_size: 8
    gradient_accumulation_steps: 4
    learning_rate: 1.0e-5
    weight_decay: 0.01

  # Router training
  router:
    epochs: 20
    batch_size: 64
    learning_rate: 1.0e-3
    weight_decay: 1.0e-4
    robust_objective: cvar  # Options: cvar, worst_case, expected
    cvar_alpha: 0.2         # Tail probability for CVaR
    cvar_epsilon: 0.3       # Max allowable CVaR failure rate
    lagrangian_lr: 0.01     # Learning rate for Lagrange multiplier
    cost_slm: 1.0
    cost_llm: 50.0

  # Overall loss weights
  lambda_pref: 0.5
  lambda_cons: 0.1

# ---------- Data defaults ----------
data:
  num_teacher_trajectories: 500
  num_perturbation_seeds: 20
  train_ratio: 0.8
  num_candidates_per_step: 8  # K for verifier scoring
  max_episode_steps: 30

# ---------- Perturbations ----------
perturbations:
  tool_flakiness:
    enabled: true
    failure_prob: 0.15
    timeout_prob: 0.05
    stale_cache_prob: 0.10
    result_shuffle_prob: 0.20
    partial_response_prob: 0.10
    result_drop_fraction: [0.1, 0.5]  # uniform range

  partial_observability:
    enabled: true
    dom_hide_prob: 0.15
    dom_reorder_prob: 0.10
    attribute_strip_prob: 0.10
    log_truncation_prob: 0.20
    log_line_drop_prob: 0.10
    info_mask_prob: 0.05

  prompt_injection:
    enabled: true
    direct_injection_prob: 0.15
    indirect_injection_prob: 0.10
    goal_hijack_prob: 0.05
    exfiltration_attempt_prob: 0.05
    role_confusion_prob: 0.05
    encoded_injection_prob: 0.03

  distractors:
    enabled: true
    semantic_distractor_prob: 0.20
    red_herring_prob: 0.15
    decoy_element_prob: 0.10
    plausible_wrong_prob: 0.10

# ---------- Inference defaults ----------
inference:
  num_candidates: 4         # K at inference
  max_self_correct_iters: 2
  accept_threshold: 0.7
  max_llm_calls: 10         # per episode budget
  step_limit: 30

# ---------- Evaluation defaults ----------
evaluation:
  num_perturbation_seeds: 20
  num_bootstrap_samples: 1000
  confidence_level: 0.95
  cvar_alpha: 0.2
  mcnemar_significance: 0.05

# ---------- Compute ----------
compute:
  num_gpus: 4
  precision: bf16
  deepspeed_stage: 2
  gradient_checkpointing: true
  flash_attention: true

# ---------- Logging ----------
logging:
  use_wandb: true
  wandb_project: r2v-agent
  wandb_entity: null
  log_interval: 10
  eval_interval: 100
  save_interval: 500
